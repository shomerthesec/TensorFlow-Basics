{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbFmQdsZs5eW"
   },
   "outputs": [],
   "source": [
    "# ATTENTION: Please do not alter any of the provided code in the exercise. Only add your own code where indicated\n",
    "# ATTENTION: Please do not add or remove any cells in the exercise. The grader will check specific cells based on the cell position.\n",
    "# ATTENTION: Please use the provided epoch values when training.\n",
    "\n",
    "# Import all the necessary files!\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xJZ5glPPCRz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 74, 74, 32)   864         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 74, 74, 32)   96          conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 74, 74, 32)   0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 72, 72, 32)   9216        activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 72, 72, 32)   96          conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 72, 72, 32)   0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 72, 72, 64)   18432       activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 72, 72, 64)   192         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 72, 72, 64)   0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 35, 35, 80)   5120        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 35, 35, 80)   240         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 35, 35, 80)   0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 33, 33, 192)  138240      activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 33, 33, 192)  576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 33, 33, 192)  0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 16, 16, 64)   192         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 16, 16, 64)   0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 16, 16, 96)   55296       activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 16, 16, 48)   144         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 16, 16, 96)   288         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 16, 16, 48)   0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 16, 16, 96)   0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 16, 16, 64)   76800       activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 16, 16, 96)   82944       activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 16, 16, 64)   192         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 16, 16, 64)   192         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 16, 16, 96)   288         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 16, 16, 32)   96          conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 16, 16, 64)   0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 16, 16, 64)   0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 16, 16, 96)   0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 16, 16, 32)   0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_193[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 16, 16, 64)   192         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 16, 16, 64)   0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 16, 16, 96)   55296       activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 16, 16, 48)   144         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 16, 16, 96)   288         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 16, 16, 48)   0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 16, 16, 96)   0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 16, 16, 64)   76800       activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 16, 16, 96)   82944       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 16, 16, 64)   192         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 16, 16, 64)   192         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 16, 16, 96)   288         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 16, 16, 64)   192         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 16, 16, 64)   0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 16, 16, 64)   0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 16, 16, 96)   0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 16, 16, 64)   0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_200[0][0]             \n",
      "                                                                 activation_202[0][0]             \n",
      "                                                                 activation_205[0][0]             \n",
      "                                                                 activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 16, 16, 64)   192         conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 16, 16, 64)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 16, 16, 96)   55296       activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 16, 16, 48)   144         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 16, 16, 96)   288         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 16, 16, 48)   0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 16, 16, 96)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 16, 16, 64)   76800       activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 16, 16, 96)   82944       activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 16, 16, 64)   192         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 16, 16, 64)   192         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 16, 16, 96)   288         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 16, 16, 64)   192         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 16, 16, 64)   0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 16, 16, 64)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 16, 16, 96)   0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 16, 16, 64)   0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_207[0][0]             \n",
      "                                                                 activation_209[0][0]             \n",
      "                                                                 activation_212[0][0]             \n",
      "                                                                 activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 16, 16, 64)   192         conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 16, 16, 64)   0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 16, 16, 96)   55296       activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 16, 16, 96)   288         conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 16, 16, 96)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 7, 7, 96)     82944       activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 7, 7, 384)    1152        conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 7, 7, 96)     288         conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 7, 7, 384)    0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 7, 7, 96)     0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_214[0][0]             \n",
      "                                                                 activation_217[0][0]             \n",
      "                                                                 max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 7, 7, 128)    384         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 7, 7, 128)    0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 7, 7, 128)    114688      activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 7, 7, 128)    384         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 7, 7, 128)    0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 7, 7, 128)    114688      activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 7, 7, 128)    384         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 7, 7, 128)    384         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 7, 7, 128)    0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 7, 7, 128)    0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 7, 7, 128)    114688      activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 7, 7, 128)    114688      activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 7, 7, 128)    384         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 7, 7, 128)    384         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 7, 7, 128)    0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 7, 7, 128)    0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_21 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 7, 7, 192)    172032      activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 7, 7, 192)    172032      activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 7, 7, 192)    576         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 7, 7, 192)    576         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 7, 7, 192)    576         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 7, 7, 192)    576         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 7, 7, 192)    0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 7, 7, 192)    0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 7, 7, 192)    0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 7, 7, 192)    0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_218[0][0]             \n",
      "                                                                 activation_221[0][0]             \n",
      "                                                                 activation_226[0][0]             \n",
      "                                                                 activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 7, 7, 160)    480         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 7, 7, 160)    0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 7, 7, 160)    179200      activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 7, 7, 160)    480         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 7, 7, 160)    0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 7, 7, 160)    179200      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 7, 7, 160)    480         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 7, 7, 160)    480         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 7, 7, 160)    0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 7, 7, 160)    0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 7, 7, 160)    179200      activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 7, 7, 160)    179200      activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 7, 7, 160)    480         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 7, 7, 160)    480         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 7, 7, 160)    0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 7, 7, 160)    0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_22 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 7, 7, 192)    215040      activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 7, 7, 192)    215040      activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 7, 7, 192)    576         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 7, 7, 192)    576         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 7, 7, 192)    576         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 7, 7, 192)    576         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 7, 7, 192)    0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 7, 7, 192)    0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 7, 7, 192)    0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 7, 7, 192)    0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_228[0][0]             \n",
      "                                                                 activation_231[0][0]             \n",
      "                                                                 activation_236[0][0]             \n",
      "                                                                 activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 7, 7, 160)    480         conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 7, 7, 160)    0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 7, 7, 160)    179200      activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 7, 7, 160)    480         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 7, 7, 160)    0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 7, 7, 160)    179200      activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 7, 7, 160)    480         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 7, 7, 160)    480         conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 7, 7, 160)    0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 7, 7, 160)    0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 7, 7, 160)    179200      activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 7, 7, 160)    179200      activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 7, 7, 160)    480         conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 7, 7, 160)    480         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 7, 7, 160)    0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 7, 7, 160)    0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_23 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 7, 7, 192)    215040      activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 7, 7, 192)    215040      activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 7, 7, 192)    576         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 7, 7, 192)    576         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 7, 7, 192)    576         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 7, 7, 192)    576         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 7, 7, 192)    0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 7, 7, 192)    0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 7, 7, 192)    0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 7, 7, 192)    0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_238[0][0]             \n",
      "                                                                 activation_241[0][0]             \n",
      "                                                                 activation_246[0][0]             \n",
      "                                                                 activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 7, 7, 192)    576         conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 7, 7, 192)    0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 7, 7, 192)    258048      activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 7, 7, 192)    576         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 7, 7, 192)    0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 7, 7, 192)    258048      activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 7, 7, 192)    576         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 7, 7, 192)    576         conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 7, 7, 192)    0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 7, 7, 192)    0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 7, 7, 192)    258048      activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 7, 7, 192)    258048      activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 7, 7, 192)    576         conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 7, 7, 192)    576         conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 7, 7, 192)    0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 7, 7, 192)    0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 7, 7, 192)    258048      activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 7, 7, 192)    258048      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 7, 7, 192)    576         conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 7, 7, 192)    576         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 7, 7, 192)    576         conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 7, 7, 192)    576         conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 7, 7, 192)    0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 7, 7, 192)    0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 7, 7, 192)    0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 7, 7, 192)    0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
      "                                                                 activation_251[0][0]             \n",
      "                                                                 activation_256[0][0]             \n",
      "                                                                 activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 7, 7, 192)    576         conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 7, 7, 192)    0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 7, 7, 192)    258048      activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 7, 7, 192)    576         conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 7, 7, 192)    0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 7, 7, 192)    258048      activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 7, 7, 192)    576         conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, 7, 7, 192)    576         conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 7, 7, 192)    0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 7, 7, 192)    0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 3, 3, 320)    552960      activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 3, 3, 192)    331776      activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 3, 3, 320)    960         conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, 3, 3, 192)    576         conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 3, 3, 320)    0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 3, 3, 192)    0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_259[0][0]             \n",
      "                                                                 activation_263[0][0]             \n",
      "                                                                 max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 3, 3, 448)    1344        conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 3, 3, 448)    0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 3, 3, 384)    1548288     activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, 3, 3, 384)    1152        conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 3, 3, 384)    1152        conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 3, 3, 384)    0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 3, 3, 384)    0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 3, 3, 384)    442368      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 3, 3, 384)    442368      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 3, 3, 384)    442368      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 3, 3, 384)    442368      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_25 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, 3, 3, 384)    1152        conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, 3, 3, 384)    1152        conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, 3, 3, 384)    1152        conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 3, 3, 384)    1152        conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, 3, 3, 320)    960         conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 3, 3, 384)    0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 3, 3, 384)    0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 3, 3, 384)    0           batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 3, 3, 384)    0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 3, 3, 192)    576         conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 3, 3, 320)    0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_266[0][0]             \n",
      "                                                                 activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 3, 3, 768)    0           activation_270[0][0]             \n",
      "                                                                 activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 3, 3, 192)    0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_264[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 3, 3, 448)    1344        conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 3, 3, 448)    0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 3, 3, 384)    1548288     activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 3, 3, 384)    1152        conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 3, 3, 384)    1152        conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 3, 3, 384)    0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 3, 3, 384)    0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 3, 3, 384)    442368      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 3, 3, 384)    442368      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 3, 3, 384)    442368      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 3, 3, 384)    442368      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_26 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 3, 3, 384)    1152        conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 3, 3, 384)    1152        conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 3, 3, 384)    1152        conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 3, 3, 384)    1152        conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 3, 3, 320)    960         conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 3, 3, 384)    0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 3, 3, 384)    0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 3, 3, 384)    0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 3, 3, 384)    0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
      "                                                                 activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
      "                                                                 activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 activation_281[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "path_inception = f\"{getcwd()}/../tmp2/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "# Import the inception model  \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# Create an instance of the inception model from the local pre-trained weights\n",
    "local_weights_file = path_inception\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), include_top = False , weights = None ) # Your Code Here\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# Make all the layers in the pre-trained model non-trainable\n",
    "for layer in pre_trained_model.layers:\n",
    "  # Your Code Here\n",
    "  layer.trainable=False\n",
    "# Print the model summary\n",
    "pre_trained_model.summary()\n",
    "\n",
    "# Expected Output is extremely large, but should end with:\n",
    "\n",
    "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
    "#                                                                 activation_276[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
    "#                                                                 activation_280[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
    "#                                                                 mixed9_1[0][0]                   \n",
    "#                                                                 concatenate_5[0][0]              \n",
    "#                                                                 activation_281[0][0]             \n",
    "#==================================================================================================\n",
    "#Total params: 21,802,784\n",
    "#Trainable params: 0\n",
    "#Non-trainable params: 21,802,784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CFsUlwdfs_wg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output # Your Code Here\n",
    "\n",
    "# Expected Output:\n",
    "# ('last layer output shape: ', (None, 7, 7, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bsWZWp5oMq9"
   },
   "outputs": [],
   "source": [
    "# Define a Callback class that stops training once accuracy reaches 97.0%\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    " def on_epoch_end(self, epoch, logs={}):\n",
    "   if(logs.get('acc')>0.97):\n",
    "        print(\"\\nReached 97.0% accuracy so cancelling training!\")\n",
    "        self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMXb913pbvFg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 74, 74, 32)   864         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 74, 74, 32)   96          conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 74, 74, 32)   0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 72, 72, 32)   9216        activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 72, 72, 32)   96          conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 72, 72, 32)   0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 72, 72, 64)   18432       activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 72, 72, 64)   192         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 72, 72, 64)   0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 35, 35, 80)   5120        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 35, 35, 80)   240         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 35, 35, 80)   0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 33, 33, 192)  138240      activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 33, 33, 192)  576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 33, 33, 192)  0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 16, 16, 64)   192         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 16, 16, 64)   0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 16, 16, 96)   55296       activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 16, 16, 48)   144         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 16, 16, 96)   288         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 16, 16, 48)   0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 16, 16, 96)   0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 16, 16, 64)   76800       activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 16, 16, 96)   82944       activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 16, 16, 64)   192         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 16, 16, 64)   192         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 16, 16, 96)   288         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 16, 16, 32)   96          conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 16, 16, 64)   0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 16, 16, 64)   0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 16, 16, 96)   0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 16, 16, 32)   0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_193[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 16, 16, 64)   192         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 16, 16, 64)   0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 16, 16, 96)   55296       activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 16, 16, 48)   144         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 16, 16, 96)   288         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 16, 16, 48)   0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 16, 16, 96)   0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 16, 16, 64)   76800       activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 16, 16, 96)   82944       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 16, 16, 64)   192         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 16, 16, 64)   192         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 16, 16, 96)   288         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 16, 16, 64)   192         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 16, 16, 64)   0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 16, 16, 64)   0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 16, 16, 96)   0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 16, 16, 64)   0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_200[0][0]             \n",
      "                                                                 activation_202[0][0]             \n",
      "                                                                 activation_205[0][0]             \n",
      "                                                                 activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 16, 16, 64)   192         conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 16, 16, 64)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 16, 16, 96)   55296       activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 16, 16, 48)   144         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 16, 16, 96)   288         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 16, 16, 48)   0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 16, 16, 96)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 16, 16, 64)   76800       activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 16, 16, 96)   82944       activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 16, 16, 64)   192         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 16, 16, 64)   192         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 16, 16, 96)   288         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 16, 16, 64)   192         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 16, 16, 64)   0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 16, 16, 64)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 16, 16, 96)   0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 16, 16, 64)   0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_207[0][0]             \n",
      "                                                                 activation_209[0][0]             \n",
      "                                                                 activation_212[0][0]             \n",
      "                                                                 activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 16, 16, 64)   192         conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 16, 16, 64)   0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 16, 16, 96)   55296       activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 16, 16, 96)   288         conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 16, 16, 96)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 7, 7, 96)     82944       activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 7, 7, 384)    1152        conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 7, 7, 96)     288         conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 7, 7, 384)    0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 7, 7, 96)     0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_214[0][0]             \n",
      "                                                                 activation_217[0][0]             \n",
      "                                                                 max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 7, 7, 128)    384         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 7, 7, 128)    0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 7, 7, 128)    114688      activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 7, 7, 128)    384         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 7, 7, 128)    0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 7, 7, 128)    114688      activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 7, 7, 128)    384         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 7, 7, 128)    384         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 7, 7, 128)    0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 7, 7, 128)    0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 7, 7, 128)    114688      activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 7, 7, 128)    114688      activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 7, 7, 128)    384         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 7, 7, 128)    384         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 7, 7, 128)    0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 7, 7, 128)    0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_21 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 7, 7, 192)    172032      activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 7, 7, 192)    172032      activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 7, 7, 192)    576         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 7, 7, 192)    576         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 7, 7, 192)    576         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 7, 7, 192)    576         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 7, 7, 192)    0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 7, 7, 192)    0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 7, 7, 192)    0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 7, 7, 192)    0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_218[0][0]             \n",
      "                                                                 activation_221[0][0]             \n",
      "                                                                 activation_226[0][0]             \n",
      "                                                                 activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 7, 7, 160)    480         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 7, 7, 160)    0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 7, 7, 160)    179200      activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 7, 7, 160)    480         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 7, 7, 160)    0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 7, 7, 160)    179200      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 7, 7, 160)    480         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 7, 7, 160)    480         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 7, 7, 160)    0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 7, 7, 160)    0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 7, 7, 160)    179200      activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 7, 7, 160)    179200      activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 7, 7, 160)    480         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 7, 7, 160)    480         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 7, 7, 160)    0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 7, 7, 160)    0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_22 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 7, 7, 192)    215040      activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 7, 7, 192)    215040      activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 7, 7, 192)    576         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 7, 7, 192)    576         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 7, 7, 192)    576         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 7, 7, 192)    576         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 7, 7, 192)    0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 7, 7, 192)    0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 7, 7, 192)    0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 7, 7, 192)    0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_228[0][0]             \n",
      "                                                                 activation_231[0][0]             \n",
      "                                                                 activation_236[0][0]             \n",
      "                                                                 activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 7, 7, 160)    480         conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 7, 7, 160)    0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 7, 7, 160)    179200      activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 7, 7, 160)    480         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 7, 7, 160)    0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 7, 7, 160)    179200      activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 7, 7, 160)    480         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 7, 7, 160)    480         conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 7, 7, 160)    0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 7, 7, 160)    0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 7, 7, 160)    179200      activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 7, 7, 160)    179200      activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 7, 7, 160)    480         conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 7, 7, 160)    480         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 7, 7, 160)    0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 7, 7, 160)    0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_23 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 7, 7, 192)    215040      activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 7, 7, 192)    215040      activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 7, 7, 192)    576         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 7, 7, 192)    576         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 7, 7, 192)    576         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 7, 7, 192)    576         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 7, 7, 192)    0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 7, 7, 192)    0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 7, 7, 192)    0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 7, 7, 192)    0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_238[0][0]             \n",
      "                                                                 activation_241[0][0]             \n",
      "                                                                 activation_246[0][0]             \n",
      "                                                                 activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 7, 7, 192)    576         conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 7, 7, 192)    0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 7, 7, 192)    258048      activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 7, 7, 192)    576         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 7, 7, 192)    0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 7, 7, 192)    258048      activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 7, 7, 192)    576         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 7, 7, 192)    576         conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 7, 7, 192)    0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 7, 7, 192)    0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 7, 7, 192)    258048      activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 7, 7, 192)    258048      activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 7, 7, 192)    576         conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 7, 7, 192)    576         conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 7, 7, 192)    0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 7, 7, 192)    0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 7, 7, 192)    258048      activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 7, 7, 192)    258048      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 7, 7, 192)    576         conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 7, 7, 192)    576         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 7, 7, 192)    576         conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 7, 7, 192)    576         conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 7, 7, 192)    0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 7, 7, 192)    0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 7, 7, 192)    0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 7, 7, 192)    0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
      "                                                                 activation_251[0][0]             \n",
      "                                                                 activation_256[0][0]             \n",
      "                                                                 activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 37632)        0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 1024)         38536192    flatten_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 1024)         0           dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 1)            1025        dropout_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 47,512,481\n",
      "Trainable params: 38,537,217\n",
      "Non-trainable params: 8,975,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024,activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense  (1 , activation='sigmoid')(x)           \n",
    "\n",
    "model = Model(pre_trained_model.input, x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['acc'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Expected output will be large. Last few lines should be:\n",
    "\n",
    "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
    "#                                                                  activation_251[0][0]             \n",
    "#                                                                  activation_256[0][0]             \n",
    "#                                                                  activation_257[0][0]             \n",
    "# __________________________________________________________________________________________________\n",
    "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
    "# __________________________________________________________________________________________________\n",
    "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
    "# ==================================================================================================\n",
    "# Total params: 47,512,481\n",
    "# Trainable params: 38,537,217\n",
    "# Non-trainable params: 8,975,264\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HrnL_IQ8knWA"
   },
   "outputs": [],
   "source": [
    "# Get the Horse or Human dataset\n",
    "path_horse_or_human = f\"{getcwd()}/../tmp2/horse-or-human.zip\"\n",
    "# Get the Horse or Human Validation dataset\n",
    "path_validation_horse_or_human = f\"{getcwd()}/../tmp2/validation-horse-or-human.zip\"\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree('/tmp')\n",
    "local_zip = path_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/training')\n",
    "zip_ref.close()\n",
    "\n",
    "local_zip = path_validation_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/validation')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9okX7_ovskI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "527\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "# Define our example directories and files\n",
    "train_dir = '/tmp/training'\n",
    "validation_dir = '/tmp/validation'\n",
    "\n",
    "train_horses_dir = '/tmp/training/horses' # Your Code Here\n",
    "train_humans_dir = '/tmp/training/humans'# Your Code Here\n",
    "validation_horses_dir = '/tmp/validation/horses'# Your Code Here\n",
    "validation_humans_dir = '/tmp/validation/humans'# Your Code Here\n",
    "\n",
    "train_horses_fnames = os.listdir(train_horses_dir + '/' ) # Your Code Here\n",
    "train_humans_fnames = os.listdir(train_humans_dir + '/' ) # Your Code Here\n",
    "validation_horses_fnames = os.listdir( validation_horses_dir + '/') # Your Code Here\n",
    "validation_humans_fnames = os.listdir(validation_humans_dir + '/' ) # Your Code Here\n",
    "\n",
    "print(len(train_horses_fnames))\n",
    "print( len(train_humans_fnames))\n",
    "print(len(validation_horses_fnames) )\n",
    "print(len(validation_humans_fnames) )\n",
    "\n",
    "# Expected Output:\n",
    "# 500\n",
    "# 527\n",
    "# 128\n",
    "# 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4s8HckqGlnb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255  )\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255 )\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                   batch_size=20,\n",
    "                                                    class_mode='binary',\n",
    "                                                   target_size=(150,150))     \n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
    "                                                   batch_size=20,\n",
    "                                                    class_mode='binary',\n",
    "                                                   target_size=(150,150))\n",
    "\n",
    "# Expected Output:\n",
    "# Found 1027 images belonging to 2 classes.\n",
    "# Found 256 images belonging to 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Blhq2MAUeyGA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "100/100 - 77s - loss: 0.0459 - acc: 0.9818 - val_loss: 0.0316 - val_acc: 0.9929\n",
      "Epoch 2/3\n",
      "\n",
      "Reached 99.9% accuracy and 99% validation accuracy so cancelling training!\n",
      "100/100 - 80s - loss: 0.0013 - acc: 0.9995 - val_loss: 0.0180 - val_acc: 0.9960\n"
     ]
    }
   ],
   "source": [
    "# Run this and see how many epochs it should take before the callback\n",
    "# fires, and stops training at 97% accuracy\n",
    "\n",
    "callbacks = myCallback()\n",
    "history = model.fit_generator(train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            steps_per_epoch = 100,\n",
    "            epochs = 3,\n",
    "            validation_steps = 50,\n",
    "            verbose = 2,\n",
    "            callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C2Fp6Se9rKuL"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now click the 'Submit Assignment' button above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When you're done or would like to take a break, please run the two cells below to save your work and close the Notebook. This will free up resources for your fellow learners. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%javascript\n",
    "#<!-- Save the notebook -->\n",
    "#IPython.notebook.save_checkpoint();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%javascript\n",
    "#IPython.notebook.session.delete();\n",
    "#window.onbeforeunload = null\n",
    "#setTimeout(function() { window.close(); }, 1000);"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 7 - Question.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "convolutional-neural-networks-tensorflow",
   "graded_item_id": "csg1x",
   "launcher_item_id": "GpKYz"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
