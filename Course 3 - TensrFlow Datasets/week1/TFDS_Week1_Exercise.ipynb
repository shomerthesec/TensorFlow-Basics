{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zX4Kg8DUTKWO"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFDS and Rock, Paper, Scissors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/TensorFlow%20Deployment/Course%203%20-%20TensorFlow%20Datasets/Week%201/Exercises/TFDS_Week1_Exercise.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
    "    Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/lmoroney/dlaicourse/blob/master/TensorFlow%20Deployment/Course%203%20-%20TensorFlow%20Datasets/Week%201/Exercises/TFDS_Week1_Exercise.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
    "    View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this week's exercise you will be working with TFDS and the rock-paper-scissors dataset. You'll do a few tasks such as exploring the info of the dataset in order to figure out the name of the splits. You'll also write code to see if the dataset supports the new S3 API before creating your own versions of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T12:32:12.721404Z",
     "start_time": "2020-07-01T12:32:12.714411Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T12:32:19.386713Z",
     "start_time": "2020-07-01T12:32:13.577570Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "TTBSvHcSLBzc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• Using TensorFlow Version: 2.0.0\n"
     ]
    }
   ],
   "source": [
    "# Use all imports\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "print(\"\\u2022 Using TensorFlow Version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the Rock, Paper, Scissors Dataset\n",
    "\n",
    "In the cell below, you will extract the `rock_paper_scissors` dataset and then print its info. Take note of the splits, what they're called, and their size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T12:36:21.515675Z",
     "start_time": "2020-07-01T12:33:02.063509Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "KGsVrzy84WI2",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset rock_paper_scissors/3.0.0 (download: 219.53 MiB, generated: Unknown size, total: 219.53 MiB) to C:\\Users\\tetos\\tensorflow_datasets\\rock_paper_scissors\\3.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a3b53bfc7340668351e23e5e85e7b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Completed...', max=1.0, style=Progre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb2d1b4c2d848f1abd113724aacf0a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Size...', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'storage.googleapis.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'storage.googleapis.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to C:\\Users\\tetos\\tensorflow_datasets\\rock_paper_scissors\\3.0.0.incomplete65UQ1T\\rock_paper_scissors-train.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e910ed9f796412a8fe5bede4388abbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2520.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to C:\\Users\\tetos\\tensorflow_datasets\\rock_paper_scissors\\3.0.0.incomplete65UQ1T\\rock_paper_scissors-test.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abdb8fd33ab14c0d819f94494ab86662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=372.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset rock_paper_scissors downloaded and prepared to C:\\Users\\tetos\\tensorflow_datasets\\rock_paper_scissors\\3.0.0. Subsequent calls will reuse this data.\u001b[0m\n",
      "WARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x0000023392552678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x0000023392552678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function _get_dataset_from_filename at 0x0000023392552678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
      "    'image': Image(shape=(300, 300, 3), dtype=tf.uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
      "    'image': Image(shape=(300, 300, 3), dtype=tf.uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
      "    'image': Image(shape=(300, 300, 3), dtype=tf.uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x0000023392552678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x0000023392552678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function _get_dataset_from_filename at 0x0000023392552678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
      "    'image': Image(shape=(300, 300, 3), dtype=tf.uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
      "    'image': Image(shape=(300, 300, 3), dtype=tf.uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
      "    'image': Image(shape=(300, 300, 3), dtype=tf.uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "tfds.core.DatasetInfo(\n",
      "    name='rock_paper_scissors',\n",
      "    version=3.0.0,\n",
      "    description='Images of hands playing rock, paper, scissor game.',\n",
      "    homepage='http://laurencemoroney.com/rock-paper-scissors-dataset',\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(300, 300, 3), dtype=tf.uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "    }),\n",
      "    total_num_examples=2892,\n",
      "    splits={\n",
      "        'test': 372,\n",
      "        'train': 2520,\n",
      "    },\n",
      "    supervised_keys=('image', 'label'),\n",
      "    citation=\"\"\"@ONLINE {rps,\n",
      "    author = \"Laurence Moroney\",\n",
      "    title = \"Rock, Paper, Scissors Dataset\",\n",
      "    month = \"feb\",\n",
      "    year = \"2019\",\n",
      "    url = \"http://laurencemoroney.com/rock-paper-scissors-dataset\"\n",
      "    }\"\"\",\n",
      "    redistribution_info=,\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# EXERCISE: Use tfds.load to extract the rock_paper_scissors dataset.\n",
    "\n",
    "data, info = tfds.load('rock_paper_scissors', with_info=True)# YOUR CODE HERE\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T12:41:32.698850Z",
     "start_time": "2020-07-01T12:41:32.690851Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "epPGTUqE5Z2E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test : 372\n",
      "train : 2520\n"
     ]
    }
   ],
   "source": [
    "# EXERCISE: In the space below, write code that iterates through the splits\n",
    "# without hardcoding any keys. The code should extract 'test' and 'train' as\n",
    "# the keys, and then print out the number of items in the dataset for each key. \n",
    "# HINT: num_examples property is very useful here.\n",
    "\n",
    "for split in info.splits: \n",
    "  print( split,':',info.splits[split].num_examples )\n",
    "\n",
    "# EXPECTED OUTPUT\n",
    "# test:372\n",
    "# train:2520"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the New S3 API\n",
    "\n",
    "Before using the new S3 API, you must first find out whether the `rock_paper_scissors` dataset implements the new S3 API. In the cell below you should use version `3.*.*` of the `rock_paper_scissors` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T12:46:01.817451Z",
     "start_time": "2020-07-01T12:46:01.786466Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Ms5ld5Ov6_OP"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "S3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-ea6259c38ec8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mrps_builder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m'rock_paper_scissors:3.*.*'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# YOUR CODE HERE (Include the following arguments in your code: \"rock_paper_scissors:3.*.*\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrps_builder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimplements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExperiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mS3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Expected output:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\enum.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(cls, name)\u001b[0m\n\u001b[0;32m    347\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_member_map_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: S3"
     ]
    }
   ],
   "source": [
    "# EXERCISE: In the space below, use the tfds.builder to fetch the\n",
    "# rock_paper_scissors dataset and check to see if it supports the\n",
    "# new S3 API. \n",
    "# HINT: The builder should 'implement' something\n",
    "\n",
    "rps_builder = tfds.builder( 'rock_paper_scissors:3.*.*')# YOUR CODE HERE (Include the following arguments in your code: \"rock_paper_scissors:3.*.*\")\n",
    "\n",
    "print(rps_builder.version.implements(tfds.core.Experiment.S3))\n",
    "\n",
    "# Expected output:\n",
    "# True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create New Datasets with the S3 API\n",
    "\n",
    "Sometimes datasets are too big for prototyping. In the cell below, you will create a smaller dataset, where instead of using all of the training data and all of the test data, you instead have a `small_train` and `small_test` each of which are comprised of the first 10% of the records in their respective datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T12:47:50.418166Z",
     "start_time": "2020-07-01T12:47:49.959714Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "QMGkJW6j7Ldl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x0000023392552678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x0000023392552678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function _get_dataset_from_filename at 0x0000023392552678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
      "    'image': Image(shape=(300, 300, 3), dtype=tf.uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
      "    'image': Image(shape=(300, 300, 3), dtype=tf.uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
      "    'image': Image(shape=(300, 300, 3), dtype=tf.uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x0000023392552678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x0000023392552678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function _get_dataset_from_filename at 0x0000023392552678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
      "    'image': Image(shape=(300, 300, 3), dtype=tf.uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
      "    'image': Image(shape=(300, 300, 3), dtype=tf.uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
      "    'image': Image(shape=(300, 300, 3), dtype=tf.uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "# EXERCISE: In the space below, create two small datasets, `small_train`\n",
    "# and `small_test`, each of which are comprised of the first 10% of the\n",
    "# records in their respective datasets.\n",
    "\n",
    "small_train = tfds.load(\"rock_paper_scissors:3.*.*\",split='train[:10%]')# YOUR CODE HERE (Include the following arguments in your code: \"rock_paper_scissors:3.*.*\")\n",
    "small_test = tfds.load(\"rock_paper_scissors:3.*.*\",split='test[:10%]') # YOUR CODE HERE (Include the following arguments in your code: \"rock_paper_scissors:3.*.*\")\n",
    "\n",
    "# No expected output yet, that's in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T12:48:28.163958Z",
     "start_time": "2020-07-01T12:48:27.775519Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "SOm99-zO_nAe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "# EXERCISE: Print out the size (length) of the small versions of the datasets.\n",
    "\n",
    "print(len(list(small_train)))\n",
    "print(len(list(small_test)))\n",
    "\n",
    "# Expected output\n",
    "# 252\n",
    "# 37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original dataset doesn't have a validation set, just training and testing sets. In the cell below, you will use TFDS to create new datasets according to these rules:\n",
    "\n",
    "* `new_train`: The new training set should be the first 90% of the original training set.\n",
    "\n",
    "\n",
    "* `new_test`: The new test set should be the first 90% of the original test set.\n",
    "\n",
    "\n",
    "* `validation`: The new validation set should be the last 10% of the original training set + the last 10% of the original test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T12:51:01.020013Z",
     "start_time": "2020-07-01T12:50:58.353133Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "jL7KXYi17s_1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x0000023392552678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x0000023392552678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function _get_dataset_from_filename at 0x0000023392552678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
      "    'image': Image(shape=(300, 300, 3), dtype=tf.uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
      "    'image': Image(shape=(300, 300, 3), dtype=tf.uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
      "    'image': Image(shape=(300, 300, 3), dtype=tf.uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "2268\n",
      "WARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x0000023392552678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x0000023392552678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function _get_dataset_from_filename at 0x0000023392552678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
      "    'image': Image(shape=(300, 300, 3), dtype=tf.uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
      "    'image': Image(shape=(300, 300, 3), dtype=tf.uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
      "    'image': Image(shape=(300, 300, 3), dtype=tf.uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "335\n",
      "WARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x0000023392552678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x0000023392552678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function _get_dataset_from_filename at 0x0000023392552678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
      "    'image': Image(shape=(300, 300, 3), dtype=tf.uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
      "    'image': Image(shape=(300, 300, 3), dtype=tf.uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
      "    'image': Image(shape=(300, 300, 3), dtype=tf.uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "289\n"
     ]
    }
   ],
   "source": [
    "# EXERCISE: In the space below, create 3 new datasets according to\n",
    "# the rules indicated above.\n",
    "\n",
    "new_train = tfds.load(\"rock_paper_scissors:3.*.*\",split='train[:90%]')# YOUR CODE HERE (Include the following arguments in your code: \"rock_paper_scissors:3.*.*\")\n",
    "print(len(list(new_train)))\n",
    "\n",
    "new_test = tfds.load(\"rock_paper_scissors:3.*.*\",split='test[:90%]')# YOUR CODE HERE (Include the following arguments in your code: \"rock_paper_scissors:3.*.*\")\n",
    "print(len(list(new_test)))\n",
    "\n",
    "validation = tfds.load(\"rock_paper_scissors:3.*.*\",split='train[90%:] + test[90%:]') # YOUR CODE HERE (Include the following arguments in your code: \"rock_paper_scissors:3.*.*\")\n",
    "print(len(list(validation)))\n",
    "\n",
    "# Expected output\n",
    "# 2268\n",
    "# 335\n",
    "# 289"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TFDS_Week1_Exercise.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
